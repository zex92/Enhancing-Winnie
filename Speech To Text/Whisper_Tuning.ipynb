{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84923b7176d4cd88eb6f5a60f638486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_16_1 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_1\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_16_1 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_1\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Set the desired cache directory\n",
    "cache_dir = \"E:\\\\mp3_processing\"\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"lg\", split=\"train+validation\", use_auth_token=True, cache_dir=cache_dir)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"lg\", split=\"test\", use_auth_token=True, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer,WhisperProcessor\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"english\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Data Preparation \n",
    "\"\"\"\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    input_features = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    labels = tokenizer(batch[\"sentence\"]).input_ids\n",
    "\n",
    "    # truncate or split the sequences if they exceed the maximum length\n",
    "    max_length = 1024  # Adjust this value based on your model's maximum sequence length\n",
    "    if len(input_features) > max_length:\n",
    "        input_features = input_features[:max_length]\n",
    "    if len(labels) > max_length:\n",
    "        labels = labels[:max_length]\n",
    "    batch[\"input_features\"] = input_features\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def apply_augmentation(audio, sample_rate):\n",
    "    # Pitch shifting\n",
    "    if np.random.rand() < 0.5:\n",
    "        pitch_shift_range = (-2, 2)\n",
    "        pitch_shift = np.random.randint(*pitch_shift_range)\n",
    "        audio = librosa.effects.pitch_shift(audio, sr=sample_rate, n_steps=pitch_shift)\n",
    "    \n",
    "    # Time stretching\n",
    "    if np.random.rand() < 0.5:\n",
    "        stretch_rate = np.random.uniform(0.8, 1.2)\n",
    "        audio = librosa.effects.time_stretch(audio, rate=stretch_rate)\n",
    "    \n",
    "    # Gaussian noise injection\n",
    "    if np.random.rand() < 0.5:\n",
    "        noise_scale = 0.005\n",
    "        noise = np.random.normal(0, noise_scale, audio.shape)\n",
    "        audio = audio + noise\n",
    "        audio = np.clip(audio, -1, 1)\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    sample_rate = audio[\"sampling_rate\"]\n",
    "\n",
    "    # Apply data augmentation with a configurable probability\n",
    "    if np.random.rand() < 0.5:\n",
    "        audio_array = audio[\"array\"]\n",
    "        audio_array = apply_augmentation(audio_array, sample_rate)\n",
    "        audio[\"array\"] = audio_array\n",
    "\n",
    "    # Compute log-Mel input features from input audio array\n",
    "    input_features = feature_extractor(audio[\"array\"], sampling_rate=sample_rate).input_features[0]\n",
    "\n",
    "    # Encode target text to label ids\n",
    "    labels = tokenizer(batch[\"sentence\"]).input_ids\n",
    "\n",
    "    # Truncation\n",
    "    max_length = 1024  # Adjust this value based on your model's maximum sequence length\n",
    "    if len(input_features) > max_length:\n",
    "        input_features = input_features[:max_length]\n",
    "    if len(labels) > max_length:\n",
    "        labels = labels[:max_length]\n",
    "\n",
    "    batch[\"input_features\"] = input_features\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b13db5c77084f1b9e7d405c2ee1bba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e7cc2de53b4310a9ffd0a7164c05da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " #common_voice_processed = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load the dataset using torch.load\n",
    "#torch.save(common_voice_processed,'common_voice_processed_mid_eng_AUG.pt')\n",
    "common_voice_processed = torch.load('common_voice_processed_mid_eng_AUG.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "# Let's initialise the data collator just defined\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")\n",
    "model.config.forced_decoder_ids = None\n",
    "model.generation_config.language = \"english\"  \n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import Seq2SeqTrainingArguments\\n\\ntraining_args = Seq2SeqTrainingArguments(\\n    output_dir=\"./whisper-medium-Lg_AUG\",\\n    per_device_train_batch_size=16, \\n    gradient_accumulation_steps=1,\\n    learning_rate=1e-5,\\n    warmup_steps=500,\\n    max_steps=4000,\\n    gradient_checkpointing=True,\\n    fp16=True,\\n    evaluation_strategy=\"steps\",\\n    per_device_eval_batch_size=8,\\n    predict_with_generate=True, \\n    generation_max_length=225,\\n    save_steps=1000,\\n    eval_steps=1000,\\n    logging_steps=25,\\n    report_to=[\"tensorboard\"],\\n    load_best_model_at_end=True,\\n    metric_for_best_model=\"wer\",\\n    greater_is_better=False,\\n    push_to_hub=True,\\n)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-medium-Lg_AUG\",\n",
    "    per_device_train_batch_size=16, \n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True, \n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-mid-eng_AUG\",\n",
    "    per_device_train_batch_size=32,  # Increase batch size to utilize GPU memory\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,  # Increase eval batch size to utilize GPU memory\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=50,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model.to(device),\n",
    "    train_dataset=common_voice_processed['train'],\n",
    "    eval_dataset=common_voice_processed['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7926267d44a40dab272d08a3993ed3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0106, 'grad_norm': 20.7950439453125, 'learning_rate': 9.200000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 3.1883, 'grad_norm': 12.457552909851074, 'learning_rate': 1.9200000000000003e-06, 'epoch': 0.04}\n",
      "{'loss': 2.1165, 'grad_norm': 11.790446281433105, 'learning_rate': 2.92e-06, 'epoch': 0.06}\n",
      "{'loss': 1.3118, 'grad_norm': 10.1051607131958, 'learning_rate': 3.920000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0356, 'grad_norm': 9.566577911376953, 'learning_rate': 4.92e-06, 'epoch': 0.09}\n",
      "{'loss': 0.8957, 'grad_norm': 8.466584205627441, 'learning_rate': 5.92e-06, 'epoch': 0.11}\n",
      "{'loss': 0.7944, 'grad_norm': 7.1853790283203125, 'learning_rate': 6.92e-06, 'epoch': 0.13}\n",
      "{'loss': 0.7543, 'grad_norm': 8.216296195983887, 'learning_rate': 7.92e-06, 'epoch': 0.15}\n",
      "{'loss': 0.7401, 'grad_norm': 7.857621669769287, 'learning_rate': 8.920000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 0.6737, 'grad_norm': 6.249478816986084, 'learning_rate': 9.920000000000002e-06, 'epoch': 0.19}\n",
      "{'loss': 0.6651, 'grad_norm': 7.615647315979004, 'learning_rate': 9.86857142857143e-06, 'epoch': 0.21}\n",
      "{'loss': 0.6098, 'grad_norm': 8.016521453857422, 'learning_rate': 9.725714285714287e-06, 'epoch': 0.23}\n",
      "{'loss': 0.5911, 'grad_norm': 6.7201948165893555, 'learning_rate': 9.582857142857143e-06, 'epoch': 0.25}\n",
      "{'loss': 0.5863, 'grad_norm': 6.489060401916504, 'learning_rate': 9.440000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 0.5696, 'grad_norm': 6.594421863555908, 'learning_rate': 9.297142857142857e-06, 'epoch': 0.28}\n",
      "{'loss': 0.5511, 'grad_norm': 6.864571571350098, 'learning_rate': 9.154285714285715e-06, 'epoch': 0.3}\n",
      "{'loss': 0.5299, 'grad_norm': 7.243512153625488, 'learning_rate': 9.011428571428572e-06, 'epoch': 0.32}\n",
      "{'loss': 0.5373, 'grad_norm': 7.627889633178711, 'learning_rate': 8.86857142857143e-06, 'epoch': 0.34}\n",
      "{'loss': 0.5025, 'grad_norm': 5.664507865905762, 'learning_rate': 8.725714285714286e-06, 'epoch': 0.36}\n",
      "{'loss': 0.4966, 'grad_norm': 6.07633113861084, 'learning_rate': 8.582857142857144e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5959c2ab28d41df885f1c49ffa92a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5857741236686707, 'eval_wer': 49.546397234777984, 'eval_runtime': 9035.7324, 'eval_samples_per_second': 1.478, 'eval_steps_per_second': 0.092, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4708, 'grad_norm': 6.1445512771606445, 'learning_rate': 8.44e-06, 'epoch': 0.4}\n",
      "{'loss': 0.4689, 'grad_norm': 5.6822896003723145, 'learning_rate': 8.297142857142859e-06, 'epoch': 0.42}\n",
      "{'loss': 0.4702, 'grad_norm': 5.341933727264404, 'learning_rate': 8.154285714285715e-06, 'epoch': 0.44}\n",
      "{'loss': 0.4664, 'grad_norm': 5.366504669189453, 'learning_rate': 8.011428571428573e-06, 'epoch': 0.45}\n",
      "{'loss': 0.4639, 'grad_norm': 6.1702070236206055, 'learning_rate': 7.86857142857143e-06, 'epoch': 0.47}\n",
      "{'loss': 0.4475, 'grad_norm': 5.6362504959106445, 'learning_rate': 7.725714285714286e-06, 'epoch': 0.49}\n",
      "{'loss': 0.434, 'grad_norm': 5.721033096313477, 'learning_rate': 7.5828571428571444e-06, 'epoch': 0.51}\n",
      "{'loss': 0.423, 'grad_norm': 6.321561336517334, 'learning_rate': 7.440000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 0.4372, 'grad_norm': 6.102550983428955, 'learning_rate': 7.297142857142858e-06, 'epoch': 0.55}\n",
      "{'loss': 0.4223, 'grad_norm': 5.335416793823242, 'learning_rate': 7.154285714285715e-06, 'epoch': 0.57}\n",
      "{'loss': 0.4099, 'grad_norm': 5.7902703285217285, 'learning_rate': 7.011428571428572e-06, 'epoch': 0.59}\n",
      "{'loss': 0.4343, 'grad_norm': 6.160478115081787, 'learning_rate': 6.868571428571429e-06, 'epoch': 0.61}\n",
      "{'loss': 0.4183, 'grad_norm': 6.199945449829102, 'learning_rate': 6.725714285714287e-06, 'epoch': 0.63}\n",
      "{'loss': 0.3984, 'grad_norm': 4.523055076599121, 'learning_rate': 6.582857142857143e-06, 'epoch': 0.64}\n",
      "{'loss': 0.4049, 'grad_norm': 5.7894487380981445, 'learning_rate': 6.440000000000001e-06, 'epoch': 0.66}\n",
      "{'loss': 0.4247, 'grad_norm': 4.953096866607666, 'learning_rate': 6.297142857142857e-06, 'epoch': 0.68}\n",
      "{'loss': 0.3975, 'grad_norm': 5.381617546081543, 'learning_rate': 6.1542857142857145e-06, 'epoch': 0.7}\n",
      "{'loss': 0.3914, 'grad_norm': 5.5088372230529785, 'learning_rate': 6.011428571428572e-06, 'epoch': 0.72}\n",
      "{'loss': 0.4108, 'grad_norm': 6.354176998138428, 'learning_rate': 5.868571428571429e-06, 'epoch': 0.74}\n",
      "{'loss': 0.3805, 'grad_norm': 5.785877704620361, 'learning_rate': 5.725714285714287e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b16beb47c304182ad471be206a11352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.473019540309906, 'eval_wer': 41.73145440042541, 'eval_runtime': 8911.2303, 'eval_samples_per_second': 1.499, 'eval_steps_per_second': 0.094, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3958, 'grad_norm': 6.597301006317139, 'learning_rate': 5.582857142857143e-06, 'epoch': 0.78}\n",
      "{'loss': 0.38, 'grad_norm': 6.393946170806885, 'learning_rate': 5.4400000000000004e-06, 'epoch': 0.8}\n",
      "{'loss': 0.3871, 'grad_norm': 5.489497661590576, 'learning_rate': 5.297142857142858e-06, 'epoch': 0.82}\n",
      "{'loss': 0.3719, 'grad_norm': 5.904890060424805, 'learning_rate': 5.154285714285715e-06, 'epoch': 0.83}\n",
      "{'loss': 0.3953, 'grad_norm': 6.2761616706848145, 'learning_rate': 5.011428571428571e-06, 'epoch': 0.85}\n",
      "{'loss': 0.375, 'grad_norm': 4.486977577209473, 'learning_rate': 4.868571428571429e-06, 'epoch': 0.87}\n",
      "{'loss': 0.3528, 'grad_norm': 4.533949375152588, 'learning_rate': 4.725714285714286e-06, 'epoch': 0.89}\n",
      "{'loss': 0.3626, 'grad_norm': 6.124539852142334, 'learning_rate': 4.5828571428571435e-06, 'epoch': 0.91}\n",
      "{'loss': 0.3782, 'grad_norm': 5.480850696563721, 'learning_rate': 4.440000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 0.3762, 'grad_norm': 5.472536563873291, 'learning_rate': 4.297142857142858e-06, 'epoch': 0.95}\n",
      "{'loss': 0.3637, 'grad_norm': 6.365388870239258, 'learning_rate': 4.154285714285714e-06, 'epoch': 0.97}\n",
      "{'loss': 0.37, 'grad_norm': 5.61099910736084, 'learning_rate': 4.011428571428571e-06, 'epoch': 0.99}\n",
      "{'loss': 0.3256, 'grad_norm': 4.5424933433532715, 'learning_rate': 3.8685714285714286e-06, 'epoch': 1.0}\n",
      "{'loss': 0.2653, 'grad_norm': 3.7739717960357666, 'learning_rate': 3.7257142857142857e-06, 'epoch': 1.02}\n",
      "{'loss': 0.2527, 'grad_norm': 4.253452777862549, 'learning_rate': 3.582857142857143e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2565, 'grad_norm': 4.429591178894043, 'learning_rate': 3.44e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2536, 'grad_norm': 4.001082420349121, 'learning_rate': 3.2971428571428577e-06, 'epoch': 1.08}\n",
      "{'loss': 0.2577, 'grad_norm': 4.878544807434082, 'learning_rate': 3.154285714285715e-06, 'epoch': 1.1}\n",
      "{'loss': 0.2605, 'grad_norm': 4.106330394744873, 'learning_rate': 3.0114285714285716e-06, 'epoch': 1.12}\n",
      "{'loss': 0.2506, 'grad_norm': 4.691235065460205, 'learning_rate': 2.868571428571429e-06, 'epoch': 1.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e94b4d262e469b8ce7a7cce7f0b1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4351734519004822, 'eval_wer': 38.252592395639454, 'eval_runtime': 8891.249, 'eval_samples_per_second': 1.502, 'eval_steps_per_second': 0.094, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2486, 'grad_norm': 4.46259069442749, 'learning_rate': 2.725714285714286e-06, 'epoch': 1.16}\n",
      "{'loss': 0.2591, 'grad_norm': 3.9345345497131348, 'learning_rate': 2.582857142857143e-06, 'epoch': 1.18}\n",
      "{'loss': 0.2711, 'grad_norm': 3.9948229789733887, 'learning_rate': 2.4400000000000004e-06, 'epoch': 1.19}\n",
      "{'loss': 0.2565, 'grad_norm': 4.853420734405518, 'learning_rate': 2.297142857142857e-06, 'epoch': 1.21}\n",
      "{'loss': 0.261, 'grad_norm': 4.33436393737793, 'learning_rate': 2.1542857142857147e-06, 'epoch': 1.23}\n",
      "{'loss': 0.2465, 'grad_norm': 4.560461521148682, 'learning_rate': 2.0114285714285715e-06, 'epoch': 1.25}\n",
      "{'loss': 0.2471, 'grad_norm': 4.5200395584106445, 'learning_rate': 1.8685714285714289e-06, 'epoch': 1.27}\n",
      "{'loss': 0.2507, 'grad_norm': 4.746490478515625, 'learning_rate': 1.7257142857142858e-06, 'epoch': 1.29}\n",
      "{'loss': 0.2458, 'grad_norm': 4.873831748962402, 'learning_rate': 1.582857142857143e-06, 'epoch': 1.31}\n",
      "{'loss': 0.2495, 'grad_norm': 4.331137657165527, 'learning_rate': 1.44e-06, 'epoch': 1.33}\n",
      "{'loss': 0.2498, 'grad_norm': 4.81401252746582, 'learning_rate': 1.2971428571428574e-06, 'epoch': 1.35}\n",
      "{'loss': 0.2561, 'grad_norm': 3.913533926010132, 'learning_rate': 1.1542857142857143e-06, 'epoch': 1.36}\n",
      "{'loss': 0.2389, 'grad_norm': 5.454670429229736, 'learning_rate': 1.0114285714285715e-06, 'epoch': 1.38}\n",
      "{'loss': 0.2504, 'grad_norm': 4.169216156005859, 'learning_rate': 8.685714285714286e-07, 'epoch': 1.4}\n",
      "{'loss': 0.2348, 'grad_norm': 4.099794387817383, 'learning_rate': 7.257142857142857e-07, 'epoch': 1.42}\n",
      "{'loss': 0.2436, 'grad_norm': 4.439766883850098, 'learning_rate': 5.82857142857143e-07, 'epoch': 1.44}\n",
      "{'loss': 0.25, 'grad_norm': 4.377413749694824, 'learning_rate': 4.4e-07, 'epoch': 1.46}\n",
      "{'loss': 0.2447, 'grad_norm': 4.3607177734375, 'learning_rate': 2.9714285714285715e-07, 'epoch': 1.48}\n",
      "{'loss': 0.2415, 'grad_norm': 4.677175521850586, 'learning_rate': 1.542857142857143e-07, 'epoch': 1.5}\n",
      "{'loss': 0.2458, 'grad_norm': 4.598462104797363, 'learning_rate': 1.142857142857143e-08, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15afbf01e9004a4b8c0897d295dc1566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4154386520385742, 'eval_wer': 37.69529380483914, 'eval_runtime': 9267.7655, 'eval_samples_per_second': 1.441, 'eval_steps_per_second': 0.09, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 67990.7509, 'train_samples_per_second': 1.883, 'train_steps_per_second': 0.059, 'train_loss': 0.5294672603607178, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.5294672603607178, metrics={'train_runtime': 67990.7509, 'train_samples_per_second': 1.883, 'train_steps_per_second': 0.059, 'train_loss': 0.5294672603607178, 'epoch': 1.52})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
