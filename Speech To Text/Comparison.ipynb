{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5d49f1d98047b08613d615f991fda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_16_1 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_1\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "e:\\Masters\\Masters Project\\Luganda MP3\\Code_Speech2Text\\.venv\\lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_16_1 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_1\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "cache_dir = \"E:\\\\mp3_processing\"\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"lg\", split=\"train+validation\", use_auth_token=True, cache_dir=cache_dir)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"lg\", split=\"test\", use_auth_token=True, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration,WhisperProcessor\n",
    "\n",
    "model_checkpoint = \"./whisper-small-Swa/checkpoint-4000\"\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"swahili\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "\n",
    "def compare_transcriptions(dataset, idx, processor, model):\n",
    "    audio_file = dataset[idx][\"audio\"][\"path\"]\n",
    "    correct_text = dataset[idx][\"sentence\"]\n",
    "\n",
    "    # Load and preprocess the audio\n",
    "    audio_array, sampling_rate = librosa.load(audio_file, sr=16000)\n",
    "    input_features = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features\n",
    "\n",
    "    # Generate the model's transcription\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(input_features)\n",
    "    model_transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Compare the model's transcription with the correct text\n",
    "    print(\"Correct Transcription:\", correct_text)\n",
    "    print(\"Model Transcription:\", model_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Transcription: Bonna baabatizibwa eri Musa mu kire ne mu nnyanja.\n",
      "Model Transcription: Bannaba batizibwa eri mmosa, mukire ne mu nnyanja.\n"
     ]
    }
   ],
   "source": [
    "compare_transcriptions(common_voice[\"test\"], 10, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
